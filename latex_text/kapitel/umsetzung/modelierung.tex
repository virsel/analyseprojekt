\newpage
\subsection{Modellierung}\label{sec:modellierung}

In dieser Arbeit geht es darum den Einfluss von Stimmungsdaten bei Aktienprognosen zu untersuchen. Da der Fokus auf den Sentiment-Daten gelegt ist, wird von den Kursdaten lediglich der Schlusspreis einbezogen. Als Basismodell dient also ein LSTM-basiertes Netzwerk, welches Schlusspreise als Eingabe verarbeitet. Das Forschungsmodell nimmt eine Kombination aus Schlusspreis und Stimmungsdaten entgegen.

Insgesamt werden $2$ Experimente durchgeführt. 

Experiment $1$:    
Diese Untersuchung analysiert den Leistungsunterschied zwischen Basis- und Forschungsmodell anhand der GOOG-Aktie.

Experiment $2$:   
Bei dieser Analyse wird der gleiche Unterschied betrachtet, jedoch unter Einbeziehung aller Aktiendaten.

In den nachfolgenden Abschnitten wird zunächst auf modellübergreifende Hyperparameter eingegangen und anschließend erfolgt eine Beschreibung der Architektur von Basis- und Forschungsmodell.

\subsubsection*{Generelle Hyperparameter}\label{sec:modellierung_generell_hp}

Es gibt eine Vielzahl an Hyperparameter, welche sowohl für das Basismodell als auch für das Forschungsmodell gelten. 
In beiden Fällen erfolgt eine Aufteilung der vorverarbeiteten Daten (Kap. \ref{sec:data_prep}) in Trainings-, Validierungs- und Testdaten. Dabei wird $20\%$ der Gesamtmenge für Tests separiert und von den restlichen $80\%$ werden $15\%$ zur Validierung verwendet.
Erst nach diesem Schritt erfolgt die MinMax-Skalierung der Trainingsdaten mit Ausnahme der Embeddings auf das Intervall $0$ bis $1$, mit Hilfe der Python Bibliothek \texttt{sklearn}. Anschließend wird der gelernte Scaler auf Test- und Validierungsdaten angewandt. So wird eine unerwünschten Übertragung von Informationen aus Validierungs- und Testdaten in den Trainingskorpus verhindert. 
Für Kursdaten wird ein Fenster von $30$ vergangenen Markttagen als Modelleingabe verwendet, um den Preis eines nachfolgenden Tages vorherzusagen. Dieser Wert wurde in Experimenten einer Forschungsarbeit an der Universität Shaoguan in China als Optimum ermittelt \footcite[Tabelle 3]{xie2024deep}.
In Anlehnung an eine weitere Forschungsarbeit wird für Stimmungsdaten ein kleineres Fenster von $10$ Markttagen verwendet \footcite[Kap. 4.1]{zhang2022transformer}.
Als Verlustfunktion dient typisch für Regressionsprobleme der \ac{MSE}, welcher sich aus Modellausgabe ($\hat{y}_i$) und tatsächlichem Preis ($y_i$) ergibt (Kap. \ref{sec:theorie_evalmetrics}, Formel \ref{frm:mse}). 
Die Batch-Größe während des Trainings beträgt $64$.



\subsubsection*{Basismodell}\label{sec:modellierung_basis_goog}

Das Basismodell nimmt als Eingabe den Schlusspreis von $30$ vorangegangenen Markttagen entgegen. Um die Charakteristik der Zeitreihendaten bestmöglich zu modellieren wurde \ac{LSTM} als Hauptbestandteil des Netzwerks gewählt (Kap. \ref{sec:theorie_lstm}). So besteht das Modell zum einen aus LSTM- und vollständig verbundenen Schichten (Abb. \ref{fig:basismodell}). 
Nachdem die Eingabe eine erste \ac{LSTM}-Ebene durchlaufen hat, folgt eine Dropout-Einheit. Dies soll für bessere Generalisierbarkeit des Modells sorgen. In Anlehnung an bereits existierende Forschungsarbeiten folgt eine zweite \ac{LSTM}-Schicht \footcite[Kap. 4.2.1]{guan2020stockprice}. Auch auf ihre Ausgabe wird eine Dropout-Operation durchgeführt. Anschließend werden die Daten an eine dichte Schicht übergeben. Ihr Zweck ist die tiefe des Modells und somit dessen Komplexität zu erhöhen, um den komplexen Mustern in den Trainingsdaten gerecht zu werden. Damit dabei nicht nur lineare, sondern auch nicht-lineare Merkmale modelliert werden können, folgt darauf die Aktivierungsfunktion \ac{ReLU}. Das Ergebnis dieser Operation wird abschließend an eine vollständig verbundene Ausgabeschicht übergeben. Deren Ausgabe stellt als Vorhersage den Schlusspreis des Folgetages (Tag $31$) in skalierter Form dar.
\begin{figure}[h]
	\centering
	\caption{Basismodell}
	\includegraphics[width=.6\textwidth]{basismodell}
	\label{fig:basismodell}
	\vspace{-1.0em}
	\begin{flushleft}
		\small{Quelle: Eigene Darstellung}
	\end{flushleft}
\end{figure}
Für die Ermittlung von Neuronenanzahl in dichten Schichten, Dropout- und Lernrate wird mit Hilfe von \texttt{keras} eine automatisierte Hyperparameter-Optimierung durchgeführt (Kap. \ref{sec:theorie_keras}). Dadurch entstehen wie in Abbildung \ref{fig:basismodell} dargestellt je nach Experiment unterschiedliche Werte.

- lernrate noch herausfinden


\subsubsection*{Forschungsmodell}\label{sec:modellierung_forsch}

\begin{figure}[H]
	\centering
	\caption{Forschungsmodell}
	\includegraphics[width=1.\textwidth]{forschungsmodell}
	\label{fig:forschungsmodell}
	\vspace{-1.0em}
	\begin{flushleft}
		\small{Quelle: Eigene Darstellung}
	\end{flushleft}
\end{figure}

- Basismodell (etwas abgewandelt) + CNN \\
- spezifische hyper paramter optimierung mit keras \\
- arch unterschied bei experiment 1 und 2 ?
- aufbau der eingabe








